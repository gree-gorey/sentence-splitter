# Отчет по проекту

1. [Аналитическая записка](https://github.com/gree-gorey/sentence_splitter/blob/master/report.md#Аналитическая-записка)
  * [обзор существующих подходов](https://github.com/gree-gorey/sentence_splitter/blob/master/report.md#Обзор-существующих-подходов)
  * [обзор проблем, пути решения](https://github.com/gree-gorey/sentence_splitter/blob/master/report.md#Обзор-проблем-пути-решения)
  * [сложные случаи, с которыми пришлось бороться](https://github.com/gree-gorey/sentence_splitter/blob/master/report.md#Сложные-случаи)
2. [Описание общей архитектуры системы](https://github.com/gree-gorey/sentence_splitter/blob/master/report.md#Описание-общей-архитектуры-системы)
  * [формат входных и выходных данных](https://github.com/gree-gorey/sentence_splitter/blob/master/report.md#Формат-входных-и-выходных-данных)
  * [основные этапы, компоненты](https://github.com/gree-gorey/sentence_splitter/blob/master/report.md#Этапы-и-компоненты)
    * [графематическая нормализация](https://github.com/gree-gorey/sentence_splitter/blob/master/report.md#Графематическая-нормализация)
    * [токенизация](https://github.com/gree-gorey/sentence_splitter/blob/master/report.md#Токенизация)
    * [сегментация на предложения](https://github.com/gree-gorey/sentence_splitter/blob/master/report.md#Сегментация-на-предложения)
    * [тестирование](https://github.com/gree-gorey/sentence_splitter/blob/master/report.md#Тестирование)
  * [параметры](https://github.com/gree-gorey/sentence_splitter/blob/master/report.md#Параметры)

## Аналитическая записка

#### Обзор существующих подходов

В [статье](http://www.dialog-21.ru/digests/dialog2008/materials/html/83.htm) Урюпиной предлагается подход к разбиению текстов на русском языке на предложения. Основная мысль ― существует омонимия знаков препинания, и, например, точка в русском языке может быть означаемым не только конца предложения, но и сокращения, специального форматирования и т.д.

#### Обзор проблем, пути решения

При токенизации мы сталкиваемся с проблемой поиска частей текста, являющимися границами токенов. Если мы разбиваем текст просто по пробелам, то у нас в токены попадут знаки препинания:
> сказал,<br>
> что

С другой стороны, некоторые токены не отделены пробелами, а вместо этого отделены только знаками препинания:
> больше/меньше

Если мы станем разбивать токены не только по пробелам, но и по знакам препинания, это приведет к тому, что некоторые токены окажутся разорванными:
> http<br>
> www<br>
> dialog-21<br>
> ru<br>

Все это необходимо учитывать.

#### Сложные случаи

Сложныыые

## Описание общей архитектуры системы

#### Формат входных и выходных данных

Входные данные ― текстовые файлы, очищенные от html-разметки

Выходные данные ― текстовые файлы, в которых все токены разделены с помощью `\n`, а предложения с помощью `\n\n`

#### Этапы и компоненты

###### Графематическая нормализация

###### Токенизация

###### Сегментация на предложения

###### Тестирование

#### Параметры

все
